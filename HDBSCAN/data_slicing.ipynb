{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9305c1",
   "metadata": {},
   "source": [
    "# Data slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7caee624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = np.load(\"cluster_labels_min_df_5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5bd797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 108746 points\n",
      "Cluster 0: 69 points\n",
      "Cluster 1: 97 points\n",
      "Cluster 2: 89 points\n",
      "Cluster 3: 159 points\n",
      "Cluster 4: 78 points\n",
      "Cluster 5: 181 points\n",
      "Cluster 6: 250 points\n",
      "Cluster 7: 493 points\n",
      "Cluster 8: 1346 points\n",
      "Cluster 9: 470 points\n",
      "Cluster 10: 206 points\n",
      "Cluster 11: 144 points\n",
      "Cluster 12: 273 points\n",
      "Cluster 13: 510 points\n",
      "Cluster 14: 195 points\n",
      "Cluster 15: 69 points\n",
      "Cluster 16: 187 points\n",
      "Cluster 17: 355 points\n",
      "Cluster 18: 205 points\n",
      "Cluster 19: 227 points\n",
      "Cluster 20: 69 points\n",
      "Cluster 21: 136 points\n",
      "Cluster 22: 233 points\n",
      "Cluster 23: 165 points\n",
      "Cluster 24: 162 points\n",
      "Cluster 25: 663 points\n",
      "Cluster 26: 106 points\n",
      "Cluster 27: 928 points\n",
      "Cluster 28: 86 points\n",
      "Cluster 29: 165 points\n",
      "Cluster 30: 87 points\n",
      "Cluster 31: 543 points\n",
      "Cluster 32: 652 points\n",
      "Cluster 33: 129 points\n",
      "Cluster 34: 703 points\n",
      "Cluster 35: 93 points\n",
      "Cluster 36: 39189 points\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(labels)\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    if label == -1:\n",
    "        print(f\"Noise: {count} points\")\n",
    "    else:\n",
    "        print(f\"Cluster {label}: {count} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa6e1485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting sequences...: 100%|██████████| 400000/400000 [00:04<00:00, 98454.75it/s] \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('../dataset/movie_new2.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "def extract_sequence(line):\n",
    "    pairs = re.findall(r'\\((\\d+),\\s*(\\d+)\\)', line)\n",
    "    sequence = [int(pairs[0][0])] + [int(p[1]) for p in pairs]\n",
    "    return sequence\n",
    "sequences = [extract_sequence(line) for line in tqdm(lines, desc=\"Extracting sequences...\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2cf2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = sorted(set(movie_id for seq in sequences for movie_id in seq))\n",
    "movie_id_to_cluster = {movie_id: cluster_label for movie_id, cluster_label in zip(movie_ids, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "73d224e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "cluster_to_movies = defaultdict(list)\n",
    "for m, c in movie_id_to_cluster.items():\n",
    "    if c != -1:  # -1 通常是 noise\n",
    "        cluster_to_movies[c].append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33cc0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_user_sequences = defaultdict(list)\n",
    "cluster_to_seen_sequences = defaultdict(set)  # 新增：追蹤每個 cluster 已經加入過哪些序列\n",
    "\n",
    "for seq in sequences: \n",
    "\n",
    "    movie_list = set(seq)\n",
    "\n",
    "    if(len(movie_list) < 15):\n",
    "        continue\n",
    "\n",
    "    # 找出此 user 涉及到的所有 cluster\n",
    "    clusters_hit = set()\n",
    "    for movie_id in movie_list:\n",
    "        if movie_id in movie_id_to_cluster:\n",
    "            clusters_hit.add(movie_id_to_cluster[movie_id])\n",
    "\n",
    "    # 把該序列加到對應 cluster 的新資料集中\n",
    "    for c in clusters_hit:\n",
    "        seq_tuple = tuple(seq)  # list 無法 hash，轉成 tuple\n",
    "        if seq_tuple not in cluster_to_seen_sequences[c]:\n",
    "            cluster_to_user_sequences[c].append(seq)\n",
    "            cluster_to_seen_sequences[c].add(seq_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ab94591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(cluster_to_user_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58aceed",
   "metadata": {},
   "source": [
    "## Store the slicing data to each cluster file (cluster_{id}.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4498f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "cluster_folder = \"../dataset/cluster_movie\"\n",
    "\n",
    "# 若資料夾存在，先刪除其內容；若不存在則建立\n",
    "if os.path.exists(cluster_folder):\n",
    "    # 刪除裡面所有檔案\n",
    "    for filename in os.listdir(cluster_folder):\n",
    "        file_path = os.path.join(cluster_folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "else:\n",
    "    os.makedirs(cluster_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9cef38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id, sequences in cluster_to_user_sequences.items():\n",
    "    filename = f\"../dataset/cluster_movie/cluster_{cluster_id}.txt\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for seq in sequences:\n",
    "            pairs = [f\"({seq[i]}, {seq[i+1]})\" for i in range(len(seq) - 1)]\n",
    "            line = \"#\".join(pairs)\n",
    "            f.write(line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
